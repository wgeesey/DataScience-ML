{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d95a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n",
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy\n",
    "\n",
    "print(numpy.__version__)\n",
    "print(sklearn.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e2d6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target names: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Importing the Iris dataset from scikit-learn. This dataset contains data about three species of iris flowers.\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset and store it in a variable called iris.\n",
    "iris = load_iris()\n",
    "\n",
    "# X represents the features (inputs) of the model. In this case, X contains data about the physical measurements of the flowers.\n",
    "# Each row in X is an individual flower, and each column corresponds to one of the four features:\n",
    "# - Sepal length\n",
    "# - Sepal width\n",
    "# - Petal length\n",
    "# - Petal width\n",
    "X = iris.data  # type is of numpy.ndarray\n",
    "\n",
    "# y represents the target (output) (\"labels\") of the model. For each flower in the dataset, y tells us the flower's species.\n",
    "# The target values are numerical, with each value corresponding to a different species. This is the answer we want from our\n",
    "# model.\n",
    "# - 0: Setosa\n",
    "# - 1: Versicolor\n",
    "# - 2: Virginica\n",
    "y = iris.target\n",
    "\n",
    "# feature_names gives us the names of the four features used to describe each flower. These are the columns in the X dataset.\n",
    "# These features will be the input variables for our machine learning model.\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "# target_names tells us the names of the three species of flowers in the dataset. These will correspond to the values in y.\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Printing the names of the features (measurements of the flowers)\n",
    "print(\"Feature names:\", feature_names)\n",
    "\n",
    "# Printing the names of the target classes (types of flowers)\n",
    "print(\"Target names:\", target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c60898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features (X_train) shape: (120, 4)\n",
      "Testing features (X_test) shape: (30, 4)\n",
      "Training verification features (y_train) shape: (120,)\n",
      "Testing  verification features (y_test) shape: (30,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# klearn.model_selection.train_test_split(\n",
    "#                            *arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
    "\n",
    "# Importing the train_test_split function from scikit-learn. This function helps us split our dataset into training and \n",
    "# testing sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset (X, y) into training and testing sets.\n",
    "# - X represents the features (measurements of the flowers).\n",
    "# - y represents the target (the species of the flowers).\n",
    "# - We are using 80% of the data for training and 20% for testing (test_size=0.2 means 20% for testing).\n",
    "#   This is a common practice to ensure the model is evaluated on data it hasn't seen during training.\n",
    "# - The train_test_split function automatically shuffles the data and splits it.\n",
    "# - The random_state argument ensures reproducibility by fixing the random split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# X_train is the set of features (inputs) that will be used to train the model.\n",
    "# y_train is the set of labels (targets) that correspond to X_train, and will teach the model the correct outputs.\n",
    "# X_test is the set of features the model will use to make predictions, but it hasn't seen this data during training.\n",
    "# y_test is the true target values corresponding to X_test. After training, we compare the model's predictions to y_test \n",
    "# to evaluate its performance.\n",
    "# Training Set (X_train and y_train): The model learns the relationship between the input features (X_train) and the target \n",
    "# labels (y_train).\n",
    "# Testing Set (X_test and y_test): This subset is used to evaluate the model's performance after training. The model makes \n",
    "# predictions on X_test, and these predictions are compared to the true values in y_test to see how well the model generalizes \n",
    "# to new, unseen data\n",
    "\n",
    "# Printing the shapes of the training and testing datasets to understand how the data has been split.\n",
    "# The shape will show the number of samples (rows) and the number of features (columns) in each set.\n",
    "print(\"Training features (X_train) shape:\", X_train.shape)  # Shows how many samples and features are in the training set\n",
    "print(\"Testing features (X_test) shape:\", X_test.shape)    # Shows how many samples and features are in the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5058b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the KNeighborsClassifier from sklearn.neighbors\n",
    "# KNeighborsClassifier is a machine learning algorithm used for classification based on the proximity of data points.\n",
    "# It classifies new data points by looking at the 'k' nearest data points in the training set and using their majority class.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# n_neighbors is a parameter that defines how many of the nearest data points (neighbors) the algorithm should consider\n",
    "# when making a prediction for a new data point. \n",
    "# In this case, we are setting n_neighbors to 3, meaning the model will consider the 3 closest data points in the training set.\n",
    "# It will then assign the majority class label from these 3 neighbors as the predicted class for the new data point.\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# The `fit` method is used to train the model using the training data (`X_train` for the features and `y_train` for the target labels).\n",
    "# `X_train` contains the input features (e.g., sepal length, petal width) that describe each data point (flower).\n",
    "# `y_train` contains the correct class labels (the actual species of the flowers, such as Setosa, Versicolor, or Virginica).\n",
    "# During training, the model \"learns\" the relationship between `X_train` and `y_train` so it can make predictions later.\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# After training, the model now has learned how the input features (`X_train`) correspond to the target labels (`y_train`).\n",
    "# It has stored the training data in a way that allows it to classify new data points based on the closest neighbors.\n",
    "# Now we can use the trained model to predict the species of new flowers based on their features in `X_test`.\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# The variable `y_pred` will now contain the predicted species labels for the new data points in `X_test`.\n",
    "# These predictions are based on the majority class of the 3 nearest neighbors of each flower in `X_test` (as determined by the model).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cad5850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Importing the metrics module from sklearn to evaluate the performance of the trained model.\n",
    "# The metrics module provides various functions for assessing the accuracy, precision, recall, etc., of a model's predictions.\n",
    "from sklearn import metrics\n",
    "\n",
    "# `accuracy_score` is a function from the metrics module that calculates the accuracy of the model's predictions.\n",
    "# Accuracy is the proportion of correct predictions out of all predictions made.\n",
    "# It compares the true labels (`y_test`) with the predicted labels (`y_pred`) to compute the proportion of matches.\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# In this case, `y_test` contains the true species labels for the test data (flowers).\n",
    "# `y_pred` contains the predicted species labels for the test data (flowers) generated by the KNN model.\n",
    "# The `accuracy_score` function compares each element in `y_test` with the corresponding element in `y_pred`.\n",
    "# It returns a value between 0 and 1, where 1 means 100% accuracy (all predictions are correct),\n",
    "# and a value closer to 0 means the model performed poorly (many predictions are incorrect).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b75f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4617c374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [np.str_('versicolor'), np.str_('virginica'), np.str_('virginica')]\n"
     ]
    }
   ],
   "source": [
    "# Sample input data. Each sublist represents a single sample with 4 features:\n",
    "# [sepal length, sepal width, petal length, petal width]\n",
    "sample = [[3, 5, 4, 2], [2, 4, 3, 5], [2, 3, 4, 5]]\n",
    "\n",
    "# Use the previously trained KNN model (knn) to predict the species of each sample.\n",
    "# The .predict() method returns an array of predicted labels (target indices) based on the sample input.\n",
    "predictions = knn.predict(sample)\n",
    "\n",
    "# Map the predicted target indices (predictions) to the actual species names.\n",
    "# iris.target_names is an array of species names, and we use each predicted index to access the correct species name.\n",
    "# The model outputs the index of the predicted species in iris.target_names, so the result of pred_species is the index of the prediction name from\n",
    "# iris.target_names. This list comprehension then takes that list of indexes and for each \"p\" in predictions, pulls the name from iris.target_names.\n",
    "pred_species = [iris.target_names[p] for p in predictions]\n",
    "\n",
    "# Print out the predicted species names.\n",
    "# The f-string formats and prints the result in a readable way.\n",
    "print(f\"Predictions: {pred_species}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11b907ca-74da-4342-9bd2-7e1b1b5dc737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [np.str_('versicolor'), np.str_('virginica'), np.str_('virginica')]\n"
     ]
    }
   ],
   "source": [
    "# Model persistence: Instead of re-training the model (using knn.fit and knn.predict) each time new data is added,\n",
    "# we can save (persist) the trained model to a file. This allows us to load the trained model later and make predictions \n",
    "# without having to train it again.\n",
    "\n",
    "# Importing the 'joblib' library, which allows us to save and load Python objects (such as models).\n",
    "import joblib\n",
    "\n",
    "# Saving the trained KNN model to a file named 'mlbrain.joblib'.\n",
    "# 'joblib.dump()' serializes the model and stores it in a binary format.\n",
    "# The filename ('mlbrain.joblib') will be used later to load the model back into memory.\n",
    "joblib.dump(knn, 'mlbrain.joblib')  # stores model in a binary file\n",
    "\n",
    "# Loading the saved model back into memory.\n",
    "# 'joblib.load()' reads the binary file and recreates the trained model.\n",
    "model = joblib.load('mlbrain.joblib')\n",
    "\n",
    "# Using the loaded model to make predictions on new data (X_test).\n",
    "# The model has already been trained on some data, and now we test it with new input data (X_test).\n",
    "model.predict(X_test)\n",
    "\n",
    "# Sample data: each sublist contains 4 feature values representing individual iris flowers\n",
    "sample = [[3, 5, 4, 2], [2, 4, 3, 5], [2, 3, 4, 5]]\n",
    "\n",
    "# Using the loaded model to predict the species of the new samples (based on their features).\n",
    "# The model.predict() method returns the indices of the predicted species.\n",
    "predictions = model.predict(sample)\n",
    "\n",
    "# Mapping the predicted species indices (from model.predict()) to the actual species names.\n",
    "# iris.target_names is a list that contains the species names. \n",
    "# We use the predicted indices to retrieve the corresponding species names.\n",
    "pred_species = [iris.target_names[p] for p in predictions]\n",
    "\n",
    "# Printing out the predicted species names in a user-friendly format.\n",
    "print(f\"Predictions: {pred_species}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d4de3-5201-475c-870c-26cfdd5f9811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
